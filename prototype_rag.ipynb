{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/firdavs/surgery/firdavs_work/.venv2/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "trainer2cases = {\n",
    "    'A1': [1, 2, 6, 7, 21, 22, 33, 35],\n",
    "    'A2': [3, 4, 5, 8, 11, 12, 13, 14, 16, 18, 20, 24, 26, 28, 29, 30, 31, 32],\n",
    "    'A3': [9, 15, 17, 23, 25, 27],\n",
    "    'A4': [10, 19, 34]\n",
    "}\n",
    "valid_cases = [1, 2, 6, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 28, 29, 33]\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "aligned_fb_detection = pd.read_csv(\"results/extract_dialogue/aligned_fb_detection/LFB1_full 'all phrases'.csv\")\n",
    "rag_embeddings_dir = \"results/extract_dialogue/rag_embeddings/context+phrase\"\n",
    "\n",
    "all_annotations = {}\n",
    "for file in sorted(os.listdir(os.path.join(rag_embeddings_dir, 'annotations')), key=lambda x: int(x.split('_')[0][3:])):\n",
    "    case_id = int(file.split('_')[0][3:])\n",
    "    if file.endswith('.csv'):\n",
    "        all_annotations[case_id] = pd.read_csv(os.path.join(rag_embeddings_dir, 'annotations', file), index_col=0)\n",
    "        all_annotations[case_id].replace({'True': True, 'False': False}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_unseen(available_annotations, fb_k=None, no_fb_k=None):\n",
    "    df = pd.concat(available_annotations.values(), ignore_index=True)\n",
    "    \n",
    "    fb_k = fb_k if fb_k is not None else len(df[df['fb_instance'] == True])\n",
    "    no_fb_k = no_fb_k if no_fb_k is not None else len(df[df['fb_instance'] == False])    \n",
    "    if fb_k > len(df[df['fb_instance'] == True]) or no_fb_k > len(df[df['fb_instance'] == False]):\n",
    "        raise ValueError(\"k is greater than the number of available instances\")\n",
    "    \n",
    "    fb_df = df[df['fb_instance'] == True]\n",
    "    no_fb_df = df[df['fb_instance'] == False]\n",
    "    \n",
    "    fb_sample = fb_df.sample(fb_k)\n",
    "    no_fb_sample = no_fb_df.sample(no_fb_k)\n",
    "    \n",
    "    return fb_sample, no_fb_sample\n",
    "\n",
    "def most_similar(datapoint, model: SentenceTransformer, fb_sample, no_fb_sample, num_examples=3):\n",
    "    datapoint_embedding = np.load(datapoint['embedding_path'])\n",
    "\n",
    "    fb_sample = fb_sample.copy()\n",
    "    no_fb_sample = no_fb_sample.copy()\n",
    "    \n",
    "    fb_embeddings = np.array([np.load(path) for path in fb_sample['embedding_path']])\n",
    "    no_fb_embeddings = np.array([np.load(path) for path in no_fb_sample['embedding_path']])\n",
    "    \n",
    "    fb_sample['similarity'] = model.similarity(datapoint_embedding, fb_embeddings).T\n",
    "    no_fb_sample['similarity'] = model.similarity(datapoint_embedding, no_fb_embeddings).T\n",
    "    \n",
    "    fb_sample = fb_sample.sort_values('similarity', ascending=False).head(num_examples)\n",
    "    no_fb_sample = no_fb_sample.sort_values('similarity', ascending=False).head(num_examples)\n",
    "    \n",
    "    return fb_sample, no_fb_sample        \n",
    "    \n",
    "def sample_examples_unseen_case(datapoint, model: SentenceTransformer, num_examples=3, fb_k=None, no_fb_k=None):\n",
    "    datapoint_case_id = datapoint['case_id']\n",
    "    available_annotations = {case_id: annotations for case_id, annotations in all_annotations.items() if case_id in valid_cases and case_id != datapoint_case_id}\n",
    "    fb_sample, no_fb_sample = sample_unseen(available_annotations, fb_k, no_fb_k)\n",
    "\n",
    "    return most_similar(datapoint, model, fb_sample, no_fb_sample, num_examples)\n",
    "    \n",
    "def sample_examples_unseen_surgeon(datapoint, model: SentenceTransformer, num_examples=3, fb_k=None, no_fb_k=None):\n",
    "    datapoint_case_id = datapoint['case_id']\n",
    "    surgeon_id = None\n",
    "    for trainer, cases in trainer2cases.items():\n",
    "        if datapoint_case_id in cases:\n",
    "            surgeon_id = trainer\n",
    "            break\n",
    "        \n",
    "    available_annotations = {case_id: annotations for case_id, annotations in all_annotations.items() if case_id in valid_cases and case_id not in trainer2cases[surgeon_id]}\n",
    "\n",
    "    fb_sample, no_fb_sample = sample_unseen(available_annotations, fb_k, no_fb_k)\n",
    "    \n",
    "    return most_similar(datapoint, model, fb_sample, no_fb_sample, num_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fb_sample, no_fb_sample = sample_unseen(all_annotations)\n",
    "\n",
    "# for i in range(10):\n",
    "#     print(no_fb_sample.iloc[i]['context_dialogue'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/firdavs/surgery/firdavs_work/.venv2/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "datapoint = all_annotations[1].iloc[0]\n",
    "\n",
    "fb_examples, no_fb_examples = sample_examples_unseen_case(datapoint, model, num_examples=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  0: ['trainer': 'All right, let's clean and then can you up.']\n",
      "  1: ['trainee': 'So I've just been learning to do the bladder neck pull out with Dr. Aaron, so the way he does it, and I'm happy to do it any way you want me to do it, he goes like, he likes to go lateral first and like really define the contour of the prostate before it comes a little bit more towards the midline. Okay, don't do that.']\n",
      "  2: ['trainee': 'I didn't know I wasn't going to do it that way because I know you don't do it that way, but I'll uh...']\n",
      "  3: ['trainer': 'So let me give you kind of a, I won't.']\n",
      "  4: ['trainee': 'For the posterior part is what I'm not going to do.']\n",
      "  5: ['trainer': 'OK, so I'll stop you if you're doing something funny. All right, let's do check on the left side, just see what's a Uzi there.']\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "print(datapoint['context_dialogue'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  0: ['trainer': 'He likes to take a little bit further if you want to. If not, let's work on the other side.']\n",
      "  1: ['trainer': 'Okay, can I? I'll come back. Yeah, that's']\n",
      "  2: ['trainer': 'Can you get it deeper? Side of the bladder.']\n",
      "  3: ['trainer': 'Sorry. Now, press your left hand on the prostate. You got your left hand always has, is this, this part is all about traction.']\n",
      "  4: ['trainer': 'So drop, here, I'll do it with my sucker and I'll show you. Pull out.']\n",
      "  5: ['trainer': 'And then you can flip and tease laterally. Yes, like that. Okay? So you do it.']\n",
      "]\n",
      "0.86223257\n",
      "\n",
      "[\n",
      "  0: ['trainee': 'I think the first time getting the right thing is...']\n",
      "  1: ['trainer': 'This is the plane.']\n",
      "  2: ['trainer': 'He likes to take a little bit further if you want to. If not, let's work on the other side.']\n",
      "  3: ['trainer': 'Okay, can I? I'll come back. Yeah, that's']\n",
      "  4: ['trainer': 'Can you get it deeper? Side of the bladder.']\n",
      "  5: ['trainer': 'Sorry. Now, press your left hand on the prostate. You got your left hand always has, is this, this part is all about traction.']\n",
      "]\n",
      "0.83976704\n",
      "\n",
      "[\n",
      "  0: ['trainer': 'Okay, can I? I'll come back. Yeah, that's']\n",
      "  1: ['trainer': 'Can you get it deeper? Side of the bladder.']\n",
      "  2: ['trainer': 'Sorry. Now, press your left hand on the prostate. You got your left hand always has, is this, this part is all about traction.']\n",
      "  3: ['trainer': 'So drop, here, I'll do it with my sucker and I'll show you. Pull out.']\n",
      "  4: ['trainer': 'And then you can flip and tease laterally. Yes, like that. Okay? So you do it.']\n",
      "  5: ['trainer': 'Like you put your fourth arm there so you can free your left hand.']\n",
      "]\n",
      "0.8351316\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(fb_examples)):\n",
    "    print(fb_examples.iloc[i]['context_dialogue'])\n",
    "    print(fb_examples.iloc[i]['similarity'])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  0: ['trainer': 'This is the plane.']\n",
      "  1: ['trainer': 'He likes to take a little bit further if you want to. If not, let's work on the other side.']\n",
      "  2: ['trainer': 'Okay, can I? I'll come back. Yeah, that's']\n",
      "  3: ['trainer': 'Can you get it deeper? Side of the bladder.']\n",
      "  4: ['trainer': 'Sorry. Now, press your left hand on the prostate. You got your left hand always has, is this, this part is all about traction.']\n",
      "  5: ['trainer': 'So drop, here, I'll do it with my sucker and I'll show you. Pull out.']\n",
      "]\n",
      "0.8528582\n",
      "\n",
      "[\n",
      "  0: ['trainee': 'Keep going so this part like the contour will be yeah, yeah, yeah keep going']\n",
      "  1: ['trainee': 'Can I have a lens clean?']\n",
      "  2: ['trainer': 'probably get in now. You're wide enough. The point is you just don't want to go in a deep hole.']\n",
      "  3: ['trainer': 'Just just get in just why why you're hold on hold on why are you just yeah?']\n",
      "  4: ['trainee': 'I don't know why you're encroaching closer to the prostate. Here? Come down just a touch. Uh-huh. Right there. Go.']\n",
      "  5: ['trainer': 'Yeah, that's fine.']\n",
      "]\n",
      "0.84446657\n",
      "\n",
      "[\n",
      "  0: ['trainee': 'Yes, but it's not a cheeky smile, it's like a barely smile. Very light. Yeah, but it's following the contour of the prostate.']\n",
      "  1: ['trainee': 'Keep going so this part like the contour will be yeah, yeah, yeah keep going']\n",
      "  2: ['trainee': 'Can I have a lens clean?']\n",
      "  3: ['trainer': 'probably get in now. You're wide enough. The point is you just don't want to go in a deep hole.']\n",
      "  4: ['trainer': 'Just just get in just why why you're hold on hold on why are you just yeah?']\n",
      "  5: ['trainee': 'I don't know why you're encroaching closer to the prostate. Here? Come down just a touch. Uh-huh. Right there. Go.']\n",
      "]\n",
      "0.8404796\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(no_fb_examples)):\n",
    "    print(no_fb_examples.iloc[i]['context_dialogue'])\n",
    "    print(no_fb_examples.iloc[i]['similarity'])\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
