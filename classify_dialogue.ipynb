{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "import torch\n",
    "from models import ExtractDialogueModel\n",
    "from transcribe import whisper_transcribe\n",
    "from utils import set_openai_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_key_path = 'openai_api_key.txt'\n",
    "# openai_key_path = 'personal_openai_api_key.txt'\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "params_extract_dialogue = {\n",
    "    'speaker_diarization_model': 'pyannote/speaker-diarization-3.1',\n",
    "    'speaker_embedding_model': 'pyannote/embedding',\n",
    "    'hf_token_path': 'huggingface_token.txt',\n",
    "    'openai_key_path': openai_key_path, \n",
    "    'transcribe_fn': whisper_transcribe,\n",
    "    'full_audio_path': '../../full_audios/LFB9_full.wav',\n",
    "    'interval': 180,\n",
    "    'console_times_path': '../../annotations/console_times/combined_console_times_secs.csv',\n",
    "    'fb_annot_path': '../../clips_no_wiggle/fbk_cuts_no_wiggle_0_4210.csv',\n",
    "    'vad_activity_path': '../../full_VADs/LFB1_full_activity.csv',\n",
    "    'diarizations_save_path': 'results/extract_dialogue/diarizations/LFB9_full.csv',\n",
    "    'transcriptions_save_path': 'results/extract_dialogue/transcriptions/LFB9_full.csv',\n",
    "    'identifications_save_path': 'results/extract_dialogue/identifications/LFB9_full.csv',\n",
    "    'fb_detection_save_path': \"results/extract_dialogue/fb_detection/LFB9_full 'all phrases'.csv\",\n",
    "    'audio_clips_dir': 'results/extract_dialogue/audio_clips',\n",
    "    'trainer_anchors_dir': 'results/extract_dialogue/anchors/trainer',\n",
    "    'trainee_anchors_dir': 'results/extract_dialogue/anchors/trainee',\n",
    "    'tmp_dir': 'tmp',\n",
    "    'seed': 42,\n",
    "    'min_n_speakers': 2,\n",
    "    'max_n_speakers': 2,\n",
    "    'embedding_dist_thresh': 0.8\n",
    "}\n",
    "set_openai_key(openai_key_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.2.7 to v2.4.0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../../../.cache/torch/pyannote/models--pyannote--embedding/snapshots/4db4899737a38b2d618bbd74350915aa10293cb2/pytorch_model.bin`\n",
      "Lightning automatically upgraded your loaded checkpoint from v1.2.7 to v2.4.0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../../../.cache/torch/pyannote/models--pyannote--embedding/snapshots/4db4899737a38b2d618bbd74350915aa10293cb2/pytorch_model.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.3.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.8.1+cu102, yours is 2.4.0+cu118. Bad things might happen unless you revert torch to 1.x.\n",
      "Model was trained with pyannote.audio 0.0.1, yours is 3.3.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.8.1+cu102, yours is 2.4.0+cu118. Bad things might happen unless you revert torch to 1.x.\n"
     ]
    }
   ],
   "source": [
    "model = ExtractDialogueModel(params_extract_dialogue, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.full_diarization(load_saved=True)\n",
    "model.full_transcription(load_saved=True)\n",
    "model.full_identification(load_saved=True)\n",
    "model.full_fb_detection(load_saved=True)\n",
    "model.full_aligned_fb_detection(load_saved=True)\n",
    "behavior_pred = model.full_behavior_prediction(load_saved=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "t, p = model.evaluate(weighting='binary', model_type='fb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6753246753246753, 0.5, 0.574585635359116, None)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "export = pd.read_csv(\"results/extract_dialogue/aligned_fb_detection/LFB9_full 'all phrases'.csv\")\n",
    "export[['pred_fb_instance', 'true_fb_instance']]\n",
    "true = export['true_fb_instance']\n",
    "pred = export['pred_fb_instance']\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, roc_auc_score\n",
    "\n",
    "precision_recall_fscore_support(true, pred, average='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "310"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(export)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(true_fb_instance\n",
       " False    102\n",
       " True      73\n",
       " Name: count, dtype: int64,\n",
       " pred_fb_instance\n",
       " False    94\n",
       " True     81\n",
       " Name: count, dtype: int64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true.value_counts(), pred.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(pred_fb_instance\n",
       " 0    233\n",
       " 1     77\n",
       " Name: count, dtype: int64,\n",
       " true_fb_instance\n",
       " 0    206\n",
       " 1    104\n",
       " Name: count, dtype: int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.value_counts(), p.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'precision_r_t_verb': 0.5454545454545454,\n",
       " 'recall_r_t_verb': 0.8571428571428571,\n",
       " 'f1_r_t_verb': 0.6666666666666666,\n",
       " 'accuracy_r_t_verb': 0.5384615384615384,\n",
       " 'roc_auc_r_t_verb': 0.5119047619047619,\n",
       " 'precision_r_t_beh': 0.7878787878787878,\n",
       " 'recall_r_t_beh': 0.7027027027027027,\n",
       " 'f1_r_t_beh': 0.7428571428571429,\n",
       " 'accuracy_r_t_beh': 0.6538461538461539,\n",
       " 'roc_auc_r_t_beh': 0.618018018018018,\n",
       " 'precision_r_t_clarify': 0.0,\n",
       " 'recall_r_t_clarify': 0.0,\n",
       " 'f1_r_t_clarify': 0.0,\n",
       " 'accuracy_r_t_clarify': 0.9807692307692307,\n",
       " 'roc_auc_r_t_clarify': None}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(weighting='binary', model_type='behavior')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'precision_r_t_verb': 0.5244755244755245,\n",
       " 'recall_r_t_verb': 0.5384615384615384,\n",
       " 'f1_r_t_verb': 0.47435897435897434,\n",
       " 'accuracy_r_t_verb': 0.5384615384615384,\n",
       " 'roc_auc_r_t_verb': 0.5119047619047619,\n",
       " 'precision_r_t_beh': 0.6820635504846031,\n",
       " 'recall_r_t_beh': 0.6538461538461539,\n",
       " 'f1_r_t_beh': 0.6643180349062702,\n",
       " 'accuracy_r_t_beh': 0.6538461538461539,\n",
       " 'roc_auc_r_t_beh': 0.618018018018018,\n",
       " 'precision_r_t_clarify': 1.0,\n",
       " 'recall_r_t_clarify': 0.9807692307692307,\n",
       " 'f1_r_t_clarify': 0.9902912621359223,\n",
       " 'accuracy_r_t_clarify': 0.9807692307692307,\n",
       " 'roc_auc_r_t_clarify': None}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(weighting='weighted', model_type='behavior')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'precision_r_t_verb': 0.5244755244755245,\n",
       " 'recall_r_t_verb': 0.5384615384615384,\n",
       " 'f1_r_t_verb': 0.47435897435897434,\n",
       " 'accuracy_r_t_verb': 0.5384615384615384,\n",
       " 'roc_auc_r_t_verb': 0.5119047619047619,\n",
       " 'precision_r_t_beh': 0.6820635504846031,\n",
       " 'recall_r_t_beh': 0.6538461538461539,\n",
       " 'f1_r_t_beh': 0.6643180349062702,\n",
       " 'accuracy_r_t_beh': 0.6538461538461539,\n",
       " 'roc_auc_r_t_beh': 0.618018018018018,\n",
       " 'precision_r_t_clarify': 1.0,\n",
       " 'recall_r_t_clarify': 0.9807692307692307,\n",
       " 'f1_r_t_clarify': 0.9902912621359223,\n",
       " 'accuracy_r_t_clarify': 0.9807692307692307,\n",
       " 'roc_auc_r_t_clarify': None}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(weighting='weighted', model_type='behavior')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def hms2secs(hms):\n",
    "#     h, m, s = hms.split(':')\n",
    "#     return int(h) * 3600 + int(m) * 60 + int(s)\n",
    "\n",
    "# def update_times(old_fb_annots, new_fb_annots):\n",
    "#     df = old_fb_annots.copy()\n",
    "    \n",
    "#     for case in new_fb_annots['Case'].unique():\n",
    "#         case_id = int(case.replace('LFB', ''))\n",
    "        \n",
    "#         old = old_fb_annots[old_fb_annots['Case'] == case_id]\n",
    "#         new = new_fb_annots[new_fb_annots['Case'] == case]\n",
    "        \n",
    "#         if len(old) != len(new):\n",
    "#             continue\n",
    "        \n",
    "#         offset = hms2secs(old.iloc[0]['Timestamp']) - hms2secs(old.iloc[0]['fbk_time'])\n",
    "\n",
    "#         for i in range(len(old)):\n",
    "#             old_timestamp = old.iloc[i]['Timestamp']\n",
    "#             new_timestamp = new.iloc[i]['FB Timestamp VALUES']\n",
    "            \n",
    "#             if old_timestamp != new_timestamp:\n",
    "#                 diff = hms2secs(new_timestamp) - hms2secs(old_timestamp)\n",
    "#                 print(case_id, old_timestamp, new_timestamp)\n",
    "                \n",
    "# pd.set_option('display.max_colwidth', None)\n",
    "# old_fb_annots = pd.read_csv('../../clips_no_wiggle/fbk_cuts_no_wiggle_0_4210.csv', index_col=0)\n",
    "# new_fb_annots = pd.read_csv('../../annotations/LFB Delay All Cases.csv', index_col=0)\n",
    "# update_times(old_fb_annots, new_fb_annots)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
